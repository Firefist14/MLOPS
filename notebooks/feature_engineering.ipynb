{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eca9953-b03e-49d7-95ab-eb213668a47a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, month, dayofmonth, hour\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "def feature_engineering(input_path, output_path):\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(input_path)\n",
    "\n",
    "    df = df.withColumn(\"Issued_date\", col(\"Issued_date\").cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"Issued_year\", year(\"Issued_date\")) \\\n",
    "           .withColumn(\"Issued_month\", month(\"Issued_date\")) \\\n",
    "           .withColumn(\"Issued_day\", dayofmonth(\"Issued_date\")) \\\n",
    "           .withColumn(\"Issued_hour\", hour(\"Issued_date\")) \\\n",
    "           .drop(\"Issued_date\")\n",
    "\n",
    "    drop_cols = ['Unit_ID', 'Violation_ID', 'Tract']\n",
    "    for c in drop_cols:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(c)\n",
    "\n",
    "    # # Handle categorical columns\n",
    "    # cat_cols = [c for c, t in df.dtypes if t == 'string']\n",
    "    # for c in cat_cols:\n",
    "    #     indexer = StringIndexer(inputCol=c, outputCol=c+\"_index\", handleInvalid='keep')\n",
    "    #     df = indexer.fit(df).transform(df).drop(c).withColumnRenamed(c+\"_index\", c)\n",
    "\n",
    "    df.write.mode(\"overwrite\").parquet(output_path)\n",
    "    print(f\"âœ… Feature engineered data saved at: {output_path}\")\n",
    "\n",
    "# Run manually\n",
    "input_path = \"/Volumes/workspace/default/tutorial/reduced_sample.csv\"\n",
    "output_path = \"/Volumes/workspace/default/tutorial/feature_engineered\"\n",
    "feature_engineering(input_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "976587fc-6687-4d25-ad40-29a458d94769",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "feature_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
